{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>wiki_link</th>\n",
       "      <th>title_y</th>\n",
       "      <th>original_title</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>story</th>\n",
       "      <th>summary</th>\n",
       "      <th>tagline</th>\n",
       "      <th>actors</th>\n",
       "      <th>wins_nominations</th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>box office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>tt8291224</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Uri:_The_Surgica...</td>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>138</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35112</td>\n",
       "      <td>Divided over five chapters the film chronicles...</td>\n",
       "      <td>Indian army special forces execute a covert op...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vicky Kaushal|Paresh Rawal|Mohit Raina|Yami Ga...</td>\n",
       "      <td>4 wins</td>\n",
       "      <td>11 January 2019 (USA)</td>\n",
       "      <td>25.00</td>\n",
       "      <td>342.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battalion 609</td>\n",
       "      <td>tt9472208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Battalion_609</td>\n",
       "      <td>Battalion 609</td>\n",
       "      <td>Battalion 609</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>131</td>\n",
       "      <td>War</td>\n",
       "      <td>4.1</td>\n",
       "      <td>73</td>\n",
       "      <td>The story revolves around a cricket match betw...</td>\n",
       "      <td>The story of Battalion 609 revolves around a c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vicky Ahuja|Shoaib Ibrahim|Shrikant Kamat|Elen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 January 2019 (India)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Accidental Prime Minister (film)</td>\n",
       "      <td>tt6986710</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Accidental_P...</td>\n",
       "      <td>The Accidental Prime Minister</td>\n",
       "      <td>The Accidental Prime Minister</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>112</td>\n",
       "      <td>Biography|Drama</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5549</td>\n",
       "      <td>Based on the memoir by Indian policy analyst S...</td>\n",
       "      <td>Explores Manmohan Singh's tenure as the Prime ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anupam Kher|Akshaye Khanna|Aahana Kumra|Atul S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 January 2019 (USA)</td>\n",
       "      <td>18.00</td>\n",
       "      <td>22.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Cheat India</td>\n",
       "      <td>tt8108208</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Why_Cheat_India</td>\n",
       "      <td>Why Cheat India</td>\n",
       "      <td>Why Cheat India</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>121</td>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1891</td>\n",
       "      <td>The movie focuses on existing malpractices in ...</td>\n",
       "      <td>The movie focuses on existing malpractices in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emraan Hashmi|Shreya Dhanwanthary|Snighdadeep ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 January 2019 (USA)</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evening Shadows</td>\n",
       "      <td>tt6028796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Evening_Shadows</td>\n",
       "      <td>Evening Shadows</td>\n",
       "      <td>Evening Shadows</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>102</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.3</td>\n",
       "      <td>280</td>\n",
       "      <td>While gay rights and marriage equality has bee...</td>\n",
       "      <td>Under the 'Evening Shadows' truth often plays ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mona Ambegaonkar|Ananth Narayan Mahadevan|Deva...</td>\n",
       "      <td>17 wins &amp; 1 nomination</td>\n",
       "      <td>11 January 2019 (India)</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>Samadhi (1950 film)</td>\n",
       "      <td>tt0268614</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Samadhi_(1950_film)</td>\n",
       "      <td>Samadhi</td>\n",
       "      <td>Samadhi</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>165</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21</td>\n",
       "      <td>The story is based on the true incident at INA...</td>\n",
       "      <td>The story is based on the true incident at INA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashok Kumar|Nalini Jaywant|Kuldip Kaur|Shyam|M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325</th>\n",
       "      <td>Sangram (1950 film)</td>\n",
       "      <td>tt0244182</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sangram_(1950_film)</td>\n",
       "      <td>Sangram</td>\n",
       "      <td>Sangram</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>139</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>20</td>\n",
       "      <td>After the death of his wife a policeman fails ...</td>\n",
       "      <td>After the death of his wife a policeman fails ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ashok Kumar|Nalini Jaywant|Nawab|Sajjan|Tiwari...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>Sargam (1950 film)</td>\n",
       "      <td>tt0269826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sargam_(1950_film)</td>\n",
       "      <td>Melody</td>\n",
       "      <td>Sargam</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>135</td>\n",
       "      <td>Drama|Family</td>\n",
       "      <td>6.8</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Add a Plot »</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raj Kapoor|Rehana|Om Prakash|David Abraham|Rad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 February 1957 (Iran)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>Sheesh Mahal (1950 film)</td>\n",
       "      <td>tt0243555</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/en/thum...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Sheesh_Mahal_(19...</td>\n",
       "      <td>Sheesh Mahal</td>\n",
       "      <td>Sheesh Mahal</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>144</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Thakur Jaspal Singh lives in the prestigious a...</td>\n",
       "      <td>Thakur Jaspal Singh lives in the prestigious a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sohrab Modi|Naseem Banu|Pushpa Hans|Nigar Sult...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4328</th>\n",
       "      <td>Meena Bazaar (film)</td>\n",
       "      <td>tt0213081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Meena_Bazaar_(19...</td>\n",
       "      <td>Meena Bazaar</td>\n",
       "      <td>Meena Bazaar</td>\n",
       "      <td>0</td>\n",
       "      <td>1950</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Add a Plot »</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4329 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title_x    imdb_id  \\\n",
       "0                 Uri: The Surgical Strike  tt8291224   \n",
       "1                            Battalion 609  tt9472208   \n",
       "2     The Accidental Prime Minister (film)  tt6986710   \n",
       "3                          Why Cheat India  tt8108208   \n",
       "4                          Evening Shadows  tt6028796   \n",
       "...                                    ...        ...   \n",
       "4324                   Samadhi (1950 film)  tt0268614   \n",
       "4325                   Sangram (1950 film)  tt0244182   \n",
       "4326                    Sargam (1950 film)  tt0269826   \n",
       "4327              Sheesh Mahal (1950 film)  tt0243555   \n",
       "4328                   Meena Bazaar (film)  tt0213081   \n",
       "\n",
       "                                            poster_path  \\\n",
       "0     https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "1                                                   NaN   \n",
       "2     https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "3     https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4324  https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "4325  https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "4326                                                NaN   \n",
       "4327  https://upload.wikimedia.org/wikipedia/en/thum...   \n",
       "4328                                                NaN   \n",
       "\n",
       "                                              wiki_link  \\\n",
       "0     https://en.wikipedia.org/wiki/Uri:_The_Surgica...   \n",
       "1           https://en.wikipedia.org/wiki/Battalion_609   \n",
       "2     https://en.wikipedia.org/wiki/The_Accidental_P...   \n",
       "3         https://en.wikipedia.org/wiki/Why_Cheat_India   \n",
       "4         https://en.wikipedia.org/wiki/Evening_Shadows   \n",
       "...                                                 ...   \n",
       "4324  https://en.wikipedia.org/wiki/Samadhi_(1950_film)   \n",
       "4325  https://en.wikipedia.org/wiki/Sangram_(1950_film)   \n",
       "4326   https://en.wikipedia.org/wiki/Sargam_(1950_film)   \n",
       "4327  https://en.wikipedia.org/wiki/Sheesh_Mahal_(19...   \n",
       "4328  https://en.wikipedia.org/wiki/Meena_Bazaar_(19...   \n",
       "\n",
       "                            title_y                 original_title  is_adult  \\\n",
       "0          Uri: The Surgical Strike       Uri: The Surgical Strike         0   \n",
       "1                     Battalion 609                  Battalion 609         0   \n",
       "2     The Accidental Prime Minister  The Accidental Prime Minister         0   \n",
       "3                   Why Cheat India                Why Cheat India         0   \n",
       "4                   Evening Shadows                Evening Shadows         0   \n",
       "...                             ...                            ...       ...   \n",
       "4324                        Samadhi                        Samadhi         0   \n",
       "4325                        Sangram                        Sangram         0   \n",
       "4326                         Melody                         Sargam         0   \n",
       "4327                   Sheesh Mahal                   Sheesh Mahal         0   \n",
       "4328                   Meena Bazaar                   Meena Bazaar         0   \n",
       "\n",
       "      year_of_release runtime            genres  imdb_rating  imdb_votes  \\\n",
       "0                2019     138  Action|Drama|War          8.4       35112   \n",
       "1                2019     131               War          4.1          73   \n",
       "2                2019     112   Biography|Drama          6.1        5549   \n",
       "3                2019     121       Crime|Drama          6.0        1891   \n",
       "4                2018     102             Drama          7.3         280   \n",
       "...               ...     ...               ...          ...         ...   \n",
       "4324             1950     165             Drama          6.1          21   \n",
       "4325             1950     139             Drama          6.2          20   \n",
       "4326             1950     135      Drama|Family          6.8          21   \n",
       "4327             1950     144             Drama          7.0          13   \n",
       "4328             1950      \\N             Drama          7.0           9   \n",
       "\n",
       "                                                  story  \\\n",
       "0     Divided over five chapters the film chronicles...   \n",
       "1     The story revolves around a cricket match betw...   \n",
       "2     Based on the memoir by Indian policy analyst S...   \n",
       "3     The movie focuses on existing malpractices in ...   \n",
       "4     While gay rights and marriage equality has bee...   \n",
       "...                                                 ...   \n",
       "4324  The story is based on the true incident at INA...   \n",
       "4325  After the death of his wife a policeman fails ...   \n",
       "4326                                                NaN   \n",
       "4327  Thakur Jaspal Singh lives in the prestigious a...   \n",
       "4328                                                NaN   \n",
       "\n",
       "                                                summary tagline  \\\n",
       "0     Indian army special forces execute a covert op...     NaN   \n",
       "1     The story of Battalion 609 revolves around a c...     NaN   \n",
       "2     Explores Manmohan Singh's tenure as the Prime ...     NaN   \n",
       "3     The movie focuses on existing malpractices in ...     NaN   \n",
       "4     Under the 'Evening Shadows' truth often plays ...     NaN   \n",
       "...                                                 ...     ...   \n",
       "4324  The story is based on the true incident at INA...     NaN   \n",
       "4325  After the death of his wife a policeman fails ...     NaN   \n",
       "4326                                       Add a Plot »     NaN   \n",
       "4327  Thakur Jaspal Singh lives in the prestigious a...     NaN   \n",
       "4328                                       Add a Plot »     NaN   \n",
       "\n",
       "                                                 actors  \\\n",
       "0     Vicky Kaushal|Paresh Rawal|Mohit Raina|Yami Ga...   \n",
       "1     Vicky Ahuja|Shoaib Ibrahim|Shrikant Kamat|Elen...   \n",
       "2     Anupam Kher|Akshaye Khanna|Aahana Kumra|Atul S...   \n",
       "3     Emraan Hashmi|Shreya Dhanwanthary|Snighdadeep ...   \n",
       "4     Mona Ambegaonkar|Ananth Narayan Mahadevan|Deva...   \n",
       "...                                                 ...   \n",
       "4324  Ashok Kumar|Nalini Jaywant|Kuldip Kaur|Shyam|M...   \n",
       "4325  Ashok Kumar|Nalini Jaywant|Nawab|Sajjan|Tiwari...   \n",
       "4326  Raj Kapoor|Rehana|Om Prakash|David Abraham|Rad...   \n",
       "4327  Sohrab Modi|Naseem Banu|Pushpa Hans|Nigar Sult...   \n",
       "4328                                                NaN   \n",
       "\n",
       "            wins_nominations             release_date  budget  box office  \n",
       "0                     4 wins    11 January 2019 (USA)   25.00      342.06  \n",
       "1                        NaN  11 January 2019 (India)    0.01        2.70  \n",
       "2                        NaN    11 January 2019 (USA)   18.00       22.65  \n",
       "3                        NaN    18 January 2019 (USA)   20.00       10.54  \n",
       "4     17 wins & 1 nomination  11 January 2019 (India)    2.75        2.50  \n",
       "...                      ...                      ...     ...         ...  \n",
       "4324                     NaN                      NaN     NaN         NaN  \n",
       "4325                     NaN                      NaN     NaN         NaN  \n",
       "4326                     NaN   4 February 1957 (Iran)     NaN         NaN  \n",
       "4327                     NaN                      NaN     NaN         NaN  \n",
       "4328                     NaN                      NaN     NaN         NaN  \n",
       "\n",
       "[4329 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('bollywood_data.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping columns which are not useful\n",
    "train = train.drop(['title_x','title_y', 'imdb_id', 'poster_path', 'wiki_link', 'is_adult', 'tagline', 'release_date', 'story', 'summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns for ease of references\n",
    "train = train.rename(columns={'original_title':'title', 'year_of_release':'year', 'imdb_rating':'rating', 'imdb_rating':'rating', 'imdb_votes':'votes', 'wins_nominations':'awards'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "train['box_office'] = train['box office']\n",
    "train = train.drop(['box office'], axis = 1)\n",
    "train['awards'] = train['awards'].apply(lambda x : re.sub(r'[A-Za-z]', '', str(x)))\n",
    "\n",
    "train[['wins', 'nominations']] = train.awards.str.split('&', expand= True)\n",
    "\n",
    "train['wins'] = train['wins'].str.strip()\n",
    "train['wins'] = train['wins'].apply(lambda x: 0 if x=='' else x)\n",
    "train['wins'] = train['wins'].replace(np.nan, 0)\n",
    "train['wins'] = train['wins'].astype(int)\n",
    "train['nominations'] = train['nominations'].replace(np.nan, 0)\n",
    "train['nominations'] = train['nominations'].astype(int)\n",
    "\n",
    "train['runtime'] = train['runtime'].replace('\\\\N', np.nan)\n",
    "train['runtime'] = train['runtime'].ffill()\n",
    "train['runtime'] = train['runtime'].astype(int)\n",
    "train = train[train['runtime'] >= 60]\n",
    "\n",
    "actors = train.actors.str.split('|', expand=True)\n",
    "train['lead_actor'] = actors[0]\n",
    "\n",
    "train[['genre', 'genre2', 'genre3']] = train.genres.str.split(\"|\", expand=True)\n",
    "train[['lead_actor1', 'lead_actor2', 'lead_actor3', 'lead_actor4']] = train.actors.str.split(\"|\", expand=True)[[0,1,2,3]]\n",
    "train.drop(['genres', 'awards', 'actors', 'genre2', 'genre3', 'nominations'], axis=1)\n",
    "minor_genre_list = ['Animation', 'Documentary', 'History', 'Music', 'War', 'Sci-Fi', 'Sport']\n",
    "train = train[~train['genre'].isin(minor_genre_list)]\n",
    "\n",
    "train = train.drop(['awards', 'genres','lead_actor','actors'], axis=1)\n",
    "train = train[train['year'] >= 2009]\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "train[\"success\"] = np.where(\n",
    "   (train.box_office > train.budget), \n",
    "   \"1\", \n",
    "   \"0\"\n",
    ")\n",
    "train['success'] = train['success'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>box_office</th>\n",
       "      <th>wins</th>\n",
       "      <th>nominations</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>lead_actor1</th>\n",
       "      <th>lead_actor2</th>\n",
       "      <th>lead_actor3</th>\n",
       "      <th>lead_actor4</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>2019</td>\n",
       "      <td>138</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35112</td>\n",
       "      <td>25.00</td>\n",
       "      <td>342.06</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Action</td>\n",
       "      <td>Drama</td>\n",
       "      <td>War</td>\n",
       "      <td>Vicky Kaushal</td>\n",
       "      <td>Paresh Rawal</td>\n",
       "      <td>Mohit Raina</td>\n",
       "      <td>Yami Gautam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Accidental Prime Minister</td>\n",
       "      <td>2019</td>\n",
       "      <td>112</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5549</td>\n",
       "      <td>18.00</td>\n",
       "      <td>22.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Biography</td>\n",
       "      <td>Drama</td>\n",
       "      <td>None</td>\n",
       "      <td>Anupam Kher</td>\n",
       "      <td>Akshaye Khanna</td>\n",
       "      <td>Aahana Kumra</td>\n",
       "      <td>Atul Sharma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why Cheat India</td>\n",
       "      <td>2019</td>\n",
       "      <td>121</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1891</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Crime</td>\n",
       "      <td>Drama</td>\n",
       "      <td>None</td>\n",
       "      <td>Emraan Hashmi</td>\n",
       "      <td>Shreya Dhanwanthary</td>\n",
       "      <td>Snighdadeep Chatterji</td>\n",
       "      <td>Navneet Srivastava</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evening Shadows</td>\n",
       "      <td>2018</td>\n",
       "      <td>102</td>\n",
       "      <td>7.3</td>\n",
       "      <td>280</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Drama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mona Ambegaonkar</td>\n",
       "      <td>Ananth Narayan Mahadevan</td>\n",
       "      <td>Devansh Doshi</td>\n",
       "      <td>Arpit Chaudhary</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Soni</td>\n",
       "      <td>2018</td>\n",
       "      <td>97</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1595</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Geetika Vidya Ohlyan</td>\n",
       "      <td>Saloni Batra</td>\n",
       "      <td>Vikas Shukla</td>\n",
       "      <td>Mohit Chauhan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Chandni Chowk to China</td>\n",
       "      <td>2009</td>\n",
       "      <td>154</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7266</td>\n",
       "      <td>80.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>None</td>\n",
       "      <td>Mithun Chakraborty</td>\n",
       "      <td>Akshay Kumar</td>\n",
       "      <td>Deepika Padukone</td>\n",
       "      <td>Ranvir Shorey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Familywala</td>\n",
       "      <td>2014</td>\n",
       "      <td>180</td>\n",
       "      <td>5.8</td>\n",
       "      <td>57</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Arjun Rampal</td>\n",
       "      <td>Dia Mirza</td>\n",
       "      <td>Ashok Saraf</td>\n",
       "      <td>Shoma Anand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Sunglass</td>\n",
       "      <td>2013</td>\n",
       "      <td>100</td>\n",
       "      <td>6.5</td>\n",
       "      <td>24</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Jaya Bachchan</td>\n",
       "      <td>Madhavan</td>\n",
       "      <td>Tota Roy Chowdhury</td>\n",
       "      <td>Raima Sen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Sabse Bada Sukh</td>\n",
       "      <td>2018</td>\n",
       "      <td>100</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>None</td>\n",
       "      <td>Vijay Arora</td>\n",
       "      <td>Asrani</td>\n",
       "      <td>Rajni Bala</td>\n",
       "      <td>Kumud Damle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Daaka</td>\n",
       "      <td>2019</td>\n",
       "      <td>136</td>\n",
       "      <td>7.4</td>\n",
       "      <td>38</td>\n",
       "      <td>12.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Action</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Gippy Grewal</td>\n",
       "      <td>Zareen Khan</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  year  runtime  rating  votes  budget  \\\n",
       "0         Uri: The Surgical Strike  2019      138     8.4  35112   25.00   \n",
       "2    The Accidental Prime Minister  2019      112     6.1   5549   18.00   \n",
       "3                  Why Cheat India  2019      121     6.0   1891   20.00   \n",
       "4                  Evening Shadows  2018      102     7.3    280    2.75   \n",
       "5                             Soni  2018       97     7.2   1595    0.50   \n",
       "..                             ...   ...      ...     ...    ...     ...   \n",
       "969         Chandni Chowk to China  2009      154     4.0   7266   80.00   \n",
       "970                     Familywala  2014      180     5.8     57    6.00   \n",
       "971                       Sunglass  2013      100     6.5     24    8.00   \n",
       "972                Sabse Bada Sukh  2018      100     6.1     13   10.00   \n",
       "973                          Daaka  2019      136     7.4     38   12.00   \n",
       "\n",
       "     box_office  wins  nominations      genre  genre2    genre3  \\\n",
       "0        342.06     4            0     Action   Drama       War   \n",
       "2         22.65     0            0  Biography   Drama      None   \n",
       "3         10.54     0            0      Crime   Drama      None   \n",
       "4          2.50    17            1      Drama    None      None   \n",
       "5          0.10     3            5      Drama    None      None   \n",
       "..          ...   ...          ...        ...     ...       ...   \n",
       "969      120.00     1            3     Action  Comedy      None   \n",
       "970        3.00     0            0     Comedy   Drama   Romance   \n",
       "971        5.00     0            0     Comedy   Drama  Thriller   \n",
       "972        7.00     0            0     Comedy   Drama      None   \n",
       "973       20.00     0            0     Action    None      None   \n",
       "\n",
       "              lead_actor1               lead_actor2            lead_actor3  \\\n",
       "0           Vicky Kaushal              Paresh Rawal            Mohit Raina   \n",
       "2             Anupam Kher            Akshaye Khanna           Aahana Kumra   \n",
       "3           Emraan Hashmi       Shreya Dhanwanthary  Snighdadeep Chatterji   \n",
       "4        Mona Ambegaonkar  Ananth Narayan Mahadevan          Devansh Doshi   \n",
       "5    Geetika Vidya Ohlyan              Saloni Batra           Vikas Shukla   \n",
       "..                    ...                       ...                    ...   \n",
       "969    Mithun Chakraborty              Akshay Kumar       Deepika Padukone   \n",
       "970          Arjun Rampal                 Dia Mirza            Ashok Saraf   \n",
       "971         Jaya Bachchan                  Madhavan     Tota Roy Chowdhury   \n",
       "972           Vijay Arora                    Asrani             Rajni Bala   \n",
       "973          Gippy Grewal               Zareen Khan                          \n",
       "\n",
       "            lead_actor4  success  \n",
       "0           Yami Gautam        1  \n",
       "2           Atul Sharma        1  \n",
       "3    Navneet Srivastava        0  \n",
       "4       Arpit Chaudhary        0  \n",
       "5         Mohit Chauhan        0  \n",
       "..                  ...      ...  \n",
       "969       Ranvir Shorey        1  \n",
       "970         Shoma Anand        0  \n",
       "971           Raima Sen        0  \n",
       "972         Kumud Damle        0  \n",
       "973                None        1  \n",
       "\n",
       "[961 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 961 entries, 0 to 973\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        961 non-null    object \n",
      " 1   year         961 non-null    int64  \n",
      " 2   runtime      961 non-null    int32  \n",
      " 3   rating       961 non-null    float64\n",
      " 4   votes        961 non-null    int64  \n",
      " 5   budget       961 non-null    float64\n",
      " 6   box_office   961 non-null    float64\n",
      " 7   wins         961 non-null    int32  \n",
      " 8   nominations  961 non-null    int32  \n",
      " 9   genre        961 non-null    object \n",
      " 10  genre2       762 non-null    object \n",
      " 11  genre3       424 non-null    object \n",
      " 12  lead_actor1  960 non-null    object \n",
      " 13  lead_actor2  960 non-null    object \n",
      " 14  lead_actor3  943 non-null    object \n",
      " 15  lead_actor4  906 non-null    object \n",
      " 16  success      961 non-null    int32  \n",
      "dtypes: float64(3), int32(4), int64(2), object(8)\n",
      "memory usage: 120.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_feature = ['runtime','rating', 'budget', 'box_office', 'votes', 'wins', 'nominations']\n",
    "basic_X = train[basic_feature]\n",
    "basic_y = train['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((241, 7), (241,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert basic_X.shape[0] == basic_y.shape[0]\n",
    "basic_X_train, basic_X_validate, basic_y_train, basic_y_validate = train_test_split(basic_X, basic_y)\n",
    "basic_X_validate.shape, basic_y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy / train:\t 0.9888888888888889\n",
      "Accuracy / validation:  0.9875518672199171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logres = LogisticRegression()\n",
    "logres.fit(basic_X_train, basic_y_train)\n",
    "logres_y_pred = logres.predict(basic_X_validate)\n",
    "print('Accuracy / train:\\t', cross_val_score(logres, basic_X_train, basic_y_train).mean())\n",
    "print('Accuracy / validation: ', accuracy_score(logres_y_pred, basic_y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(basic_X_train, basic_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear regression classifier on test set : 0.183597095 \n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(basic_X_validate)\n",
    "print('Accuracy of linear regression classifier on test set : {:.9f} '.format(regressor.score(basic_X_validate, basic_y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.1835970947028127\n",
      "RMSE 0.45036890088973525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(\"R2 score\", r2_score(basic_y_validate, y_pred))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(basic_y_validate, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.1360e+01 3.2000e+01 5.8650e+01 5.0000e+00 6.6320e+01 1.9700e+02\n 3.0000e+00 1.1650e+01 2.2000e+02 6.3290e+01 9.1700e+01 1.7800e+02\n 3.8400e+01 1.0000e+00 2.2800e+00 2.0261e+02 1.5127e+02 6.4900e+01\n 1.8800e+02 2.0000e+00 3.4960e+01 1.9000e-01 5.8685e+02 2.0280e+01\n 1.0000e-03 1.7000e-01 1.7800e+00 7.2160e+01 4.0000e-01 6.6400e+00\n 3.0200e+00 1.0800e+02 1.7600e+01 6.1000e+01 1.5831e+02 1.2000e-01\n 2.7470e+01 4.0000e-02 4.4900e+00 1.0000e+00 6.8000e+01 2.4000e+00\n 3.7000e+00 2.2200e+00 3.9760e+01 3.0800e+02 1.5000e-01 4.7000e+01\n 1.0000e-02 6.2400e+00 5.8410e+01 3.2500e+02 1.0000e-03 6.0000e-01\n 2.4600e+00 2.3000e-01 6.0000e+01 4.0000e-02 2.0000e+00 1.9100e+00\n 1.7000e-01 6.5450e+01 1.7297e+02 1.1000e-01 1.9600e+00 1.5124e+02\n 5.2500e+00 8.3000e-03 1.4000e-02 5.6130e+01 1.8076e+02 7.2000e-01\n 2.0000e+01 2.0000e-01 4.0000e-03 4.8000e-01 4.1000e+01 2.0600e+00\n 9.7000e-01 2.3093e+02 3.7500e+00 2.8000e+00 9.1710e+01 3.9000e-01\n 2.0000e-02 1.3800e+00 3.9000e+01 9.3080e+01 5.7000e-01 4.5000e+01\n 6.8000e-01 2.5300e+00 1.8000e+02 3.7000e+00 5.2320e+01 1.9000e-01\n 2.9059e+02 8.8720e+01 5.3880e+01 2.9000e-01 1.5700e+01 1.1500e+02\n 4.0460e+01 3.4820e+01 1.1040e+02 2.1927e+02 7.0000e-02 9.1000e+01\n 8.0000e-02 7.2500e+00 1.2000e+02 3.3000e-01 4.0250e+01 1.5700e+00\n 1.0500e+01 9.8000e-01 3.0000e+00 6.5000e-01 3.0000e-02 4.5720e+01\n 4.6600e+01 8.4820e+01 4.2000e-01 2.5000e+00 1.8480e+01 5.8300e+00\n 8.0000e-02 1.2600e+02 1.8000e+00 5.7900e+00 1.4200e+01 4.8000e+01\n 4.1800e+00 1.5200e+02 3.0000e-02 3.6200e+00 1.0540e+01 1.2000e-01\n 3.0620e+01 1.3581e+02 1.7100e+02 1.4000e+01 3.2400e+00 1.9500e+02\n 5.0000e-02 8.6000e+01 1.2157e+02 1.4000e-01 7.7000e+00 9.6500e+02\n 2.0000e+01 2.0000e+00 2.5700e+01 1.4300e+02 7.6300e+00 1.0000e-03\n 2.5000e-01 1.0000e+01 9.8500e+00 1.5000e-01 2.1660e+01 1.7240e+01\n 2.2800e+02 1.0400e+02 1.6700e+00 2.1510e+01 2.5000e-01 3.3000e-01\n 1.3000e+00 1.1400e+00 2.7850e+01 1.8840e+02 9.3000e-01 3.0000e-02\n 2.9900e+00 2.0000e-01 3.3000e+01 1.1600e+00 3.2890e+01 7.5000e-03\n 2.0000e-02 7.0000e-02 5.0000e-01 1.0200e+01 1.6000e+00 2.5000e-01\n 1.8200e+00 1.0000e-02 8.8170e+01 1.8000e+00 3.1100e+02 1.0400e-01\n 4.3900e+01 8.5400e+02 6.6200e+00 8.5500e+00 2.4000e-01 4.1040e+01\n 1.3400e+00 5.9200e+00 2.7000e-01 4.0400e+00 2.4000e+01 5.0000e-02\n 4.1000e+01 7.5110e+01 4.2180e+01 6.0000e+00 4.6800e+01 2.3000e+01\n 3.3100e+00 9.1260e+01 1.1000e-01 1.7000e+01 3.2700e+00 3.2600e+00\n 2.8410e+01 3.2920e+01 6.5000e-01 1.5316e+02 2.9161e+02 1.1900e+02\n 3.0000e+01 1.2414e+02 1.0540e+01 6.1000e-01 2.2700e+00 2.7000e-01\n 2.4000e+00 2.1026e+02 6.4500e+01 2.5000e+01 1.2500e+02 1.7810e+02\n 1.9400e+01 1.2700e+00 1.2300e+02 2.5000e+00 1.0900e+01 3.1900e+00\n 1.0000e-01 1.2600e+01 2.2000e-01 1.0000e+01 1.5318e+02 1.7000e-01\n 5.0000e-02 4.7100e+01 7.0000e+00 9.6800e+01 5.0000e-01 8.1700e+00\n 1.2600e+02 1.0220e+01 3.1600e+01 8.5200e+01 3.8000e+01 3.7685e+02\n 2.8000e-01 1.5000e+01 1.2000e-01 1.4298e+02 5.0000e+00 9.4850e+01\n 5.6710e+01 2.1000e+03 2.5840e+01 3.9760e+01 2.2700e+01 4.9470e+01\n 2.8600e+00 1.5732e+02 6.0000e-01 9.0000e-02 2.6100e+01 3.0000e+00\n 4.0800e+01 5.5000e-01 6.0770e+01 4.7000e+01 1.4695e+02 2.8700e+01\n 6.0000e-01 5.0000e-01 4.9000e+00 3.1150e+01 6.2500e+00 1.0000e+01\n 5.0000e+00 1.9800e+01 4.3100e+00 2.7000e+01 8.6000e-01 2.1200e+02\n 1.1580e+01 9.0000e-02 4.0000e-01 3.6000e+00 2.1114e+02 8.1650e+01\n 1.4000e-01 2.1000e+02 1.4760e+01 3.1400e+00 1.2000e+01 3.7700e+00\n 1.7000e-01 5.0000e+00 1.0000e-01 7.2600e+01 4.9590e+01 1.7473e+02\n 2.2400e+00 2.0709e+02 3.0300e+02 4.0000e+00 5.0000e+00 4.2000e-01\n 3.3500e+00 2.9000e-01 2.0000e+00 1.2500e+00 1.5000e-01 1.2000e+01\n 8.0000e-01 7.3000e+01 3.9000e-01 3.6500e+01 2.4100e+00 6.0000e+01\n 2.1600e+02 1.3900e+02 5.0000e+00 3.6000e+01 7.8900e+01 9.0300e+00\n 4.3240e+02 8.3000e+01 7.0000e-01 4.7170e+01 2.8730e+01 4.1200e+00\n 7.5000e-01 2.1656e+02 3.4206e+02 6.4000e-01 5.3700e+00 9.3000e+01\n 3.5000e+00 8.0000e+01 1.3700e+01 6.2790e+01 1.4100e+02 2.4400e+00\n 1.0398e+02 2.0000e+00 2.0000e+01 4.3100e+00 2.2200e+02 3.7000e+01\n 4.6400e+01 8.0430e+01 3.1855e+02 1.2200e+00 2.5700e+00 1.5000e-01\n 5.0000e-02 5.0000e+00 5.7500e+00 2.0600e+02 2.0380e+01 9.0000e-02\n 1.2000e+01 2.1600e+02 1.1300e+00 3.0000e+00 7.4000e+01 2.9000e+01\n 3.4000e-01 5.8800e+01 1.0362e+02 4.5700e+00 9.8200e+00 9.9700e+01\n 4.6800e+00 9.6900e+02 1.2000e-01 2.1000e-01 2.3000e-01 3.3140e+01\n 1.2700e+01 9.6660e+01 1.5275e+02 2.0000e+02 1.4613e+02 3.5000e-01\n 3.8000e+00 3.5000e-01 1.2400e+01 2.8000e+00 8.0000e+00 1.9504e+02\n 1.0400e+00 1.0000e-01 3.1070e+01 4.0000e-01 1.2300e+00 9.2500e-01\n 4.3200e+00 4.0000e-01 1.3400e+00 1.3100e+01 6.0000e-02 4.0000e-02\n 3.1000e-01 2.2000e-01 8.0000e+00 6.5000e+01 2.2000e+01 4.8000e+00\n 8.3000e-02 6.5000e-01 1.0000e+01 1.0000e+00 1.7000e+01 1.2090e+01\n 1.7500e+01 5.4000e+01 2.3500e-01 2.0000e-01 1.8750e+01 3.4600e+00\n 2.5700e+00 4.0000e-01 9.3840e+01 1.2270e+01 1.2400e+00 1.5600e+00\n 1.9500e+00 5.1000e+00 3.0000e+01 1.9860e+01 7.0000e+00 2.2400e+01\n 9.0000e-01 4.2700e+00 3.0610e+01 1.0060e+01 1.0000e+02 3.3406e+02\n 1.0000e+00 1.3500e+00 1.4500e+00 1.9300e+02 3.6000e-01 6.5000e-03\n 8.0880e+01 8.5000e-02 1.9300e+00 1.2000e-01 3.2000e-01 3.0350e+01\n 1.5300e+02 2.0000e-01 2.9500e+00 4.6000e+01 3.8000e+01 1.3900e-01\n 8.7020e+01 2.2900e+00 3.7700e+01 1.3480e+00 4.0000e+00 6.5700e+01\n 7.6000e-01 7.0000e+00 1.1460e+01 1.5300e+02 1.5143e+02 7.6600e+00\n 2.5600e+01 1.8100e+00 2.0100e+01 2.0000e-02 3.5620e+02 3.0000e-03\n 1.5000e+00 9.7180e+01 9.5000e-01 2.8000e-01 1.5000e+01 1.0000e+01\n 3.9000e-01 5.2500e+00 1.0000e-03 4.3900e+00 1.7000e-01 4.4920e+01\n 7.1000e+01 1.7800e+00 1.3000e+00 4.7500e+00 2.0000e+01 2.8060e+01\n 3.0000e+00 2.5000e+00 2.5000e+00 5.0000e-01 7.2000e-01 3.5300e+01\n 1.2900e+00 2.8400e+00 3.0490e+01 6.4900e+01 1.0900e+00 2.8027e+02\n 2.1600e+01 3.5000e+00 2.1320e+01 4.3000e+01 4.7000e-01 9.6000e-01\n 2.0000e-01 1.9400e+01 1.6310e+01 4.7000e-01 2.0000e+00 1.1000e-01\n 1.6500e+00 4.7820e+01 3.4130e+01 6.6800e+00 5.0000e-01 1.2000e-01\n 4.6230e+01 9.0000e+00 1.3900e+00 2.6000e-01 9.1000e-01 1.2920e+01\n 5.0840e+01 2.1300e+00 2.0000e+01 8.3000e-02 1.5000e-01 2.2759e+02\n 1.5750e+01 5.5000e+00 9.0000e+00 1.6500e+01 5.0000e-01 6.8000e+00\n 5.0000e-03 5.7000e-01 1.7500e+01 5.2437e+02 7.2100e+01 1.5000e+02\n 8.4800e+00 1.9100e+00 4.2000e-01 2.5041e+02 1.8200e+00 2.8000e+01\n 1.2000e+01 1.3530e+01 3.4500e+00 9.3900e+00 2.4000e+01 4.7000e+01\n 1.5500e+01 2.0000e-02 9.0000e-02 1.1060e+01 9.4000e+01 7.5000e+01\n 3.6960e+01 5.0000e-03 4.8000e-01 1.0600e+01 7.1000e+01 2.5900e+01\n 3.9870e+01 7.9000e+01 1.1000e+00 9.5800e+00 2.0148e+02 2.3000e-01\n 4.9000e+01 1.7000e+01 2.3756e+02 1.1800e+00 8.4800e+00 1.3380e+01\n 6.4540e+01 1.1170e+02 7.5000e-03 1.3849e+02 1.9500e+01 3.4500e+01\n 2.4000e-01 1.2000e-01 3.3000e+01 1.1100e+00 8.0000e-01 4.0000e-01\n 2.7200e+00 4.1800e+01 5.1582e+02 2.1800e+00 7.5700e+01 3.8302e+02\n 4.8000e+01 6.3590e+01 1.3200e+00 2.7600e+00 8.1000e-02 1.2300e+00\n 2.0700e+02 1.6148e+02 5.5800e+02 2.2000e-01 8.6030e+01 8.1000e+01\n 1.7000e+01 3.8030e+01 9.9900e+00 7.8000e+01 1.4500e+02 4.4000e-01\n 6.0000e+00 1.5000e-01 1.0000e+01 2.8800e+01 8.9500e+00 6.2000e-01\n 1.9200e+00 3.0000e-02 2.4520e+01 9.1500e+00 2.6800e+00 3.2580e+01\n 5.0000e-02 1.2870e+01 2.3010e+01 8.2400e+00 1.2000e-02 1.5500e+00\n 1.6876e+02 1.7000e+01 2.0000e+00 3.7000e-01 1.7500e+02 1.8800e+00\n 1.1500e+02 7.6000e-01 1.0740e+02 4.3964e+02 4.6500e+01 1.7590e+02\n 2.4960e+01 1.5000e+01 9.2400e+00 2.0000e+00 1.0066e+02 6.0000e+00\n 1.1100e+00 3.0250e-01 3.4000e-01 5.8200e+01 3.8000e+01 9.9250e+01\n 2.0893e+02 6.7560e+01 1.1000e-01 1.0500e+00 4.2900e+01 1.3600e+02\n 1.3000e-01 1.7000e+02 2.5300e+00 1.4900e+00 2.3050e+01 1.5300e+00\n 2.9700e+01 1.0000e-01 5.0000e-02 1.1000e+02 3.9592e+02 4.1000e+01\n 1.1076e+02 1.5000e-01 7.0000e-03 1.4000e+01 2.2000e+01 7.1000e-01\n 6.0000e-01 8.4000e+01 5.0000e-01 1.8000e+01 2.0000e-03 1.0000e-01\n 3.7000e+01 3.0000e+01 1.2000e+01 1.3000e+00 7.7000e-01 7.1000e+01\n 5.0000e-02 5.0610e+01 5.2000e+00 6.1500e+00 3.0000e-01 2.2260e+01\n 9.0000e-02 2.5000e-01 1.0500e+00 3.3500e+02 1.1380e+01 2.4500e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-1394cd246d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_X_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box_office'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasic_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_X_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box_office'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_X_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box_office'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Box Office vs Budget (Training Set)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Budget'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    220\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.1360e+01 3.2000e+01 5.8650e+01 5.0000e+00 6.6320e+01 1.9700e+02\n 3.0000e+00 1.1650e+01 2.2000e+02 6.3290e+01 9.1700e+01 1.7800e+02\n 3.8400e+01 1.0000e+00 2.2800e+00 2.0261e+02 1.5127e+02 6.4900e+01\n 1.8800e+02 2.0000e+00 3.4960e+01 1.9000e-01 5.8685e+02 2.0280e+01\n 1.0000e-03 1.7000e-01 1.7800e+00 7.2160e+01 4.0000e-01 6.6400e+00\n 3.0200e+00 1.0800e+02 1.7600e+01 6.1000e+01 1.5831e+02 1.2000e-01\n 2.7470e+01 4.0000e-02 4.4900e+00 1.0000e+00 6.8000e+01 2.4000e+00\n 3.7000e+00 2.2200e+00 3.9760e+01 3.0800e+02 1.5000e-01 4.7000e+01\n 1.0000e-02 6.2400e+00 5.8410e+01 3.2500e+02 1.0000e-03 6.0000e-01\n 2.4600e+00 2.3000e-01 6.0000e+01 4.0000e-02 2.0000e+00 1.9100e+00\n 1.7000e-01 6.5450e+01 1.7297e+02 1.1000e-01 1.9600e+00 1.5124e+02\n 5.2500e+00 8.3000e-03 1.4000e-02 5.6130e+01 1.8076e+02 7.2000e-01\n 2.0000e+01 2.0000e-01 4.0000e-03 4.8000e-01 4.1000e+01 2.0600e+00\n 9.7000e-01 2.3093e+02 3.7500e+00 2.8000e+00 9.1710e+01 3.9000e-01\n 2.0000e-02 1.3800e+00 3.9000e+01 9.3080e+01 5.7000e-01 4.5000e+01\n 6.8000e-01 2.5300e+00 1.8000e+02 3.7000e+00 5.2320e+01 1.9000e-01\n 2.9059e+02 8.8720e+01 5.3880e+01 2.9000e-01 1.5700e+01 1.1500e+02\n 4.0460e+01 3.4820e+01 1.1040e+02 2.1927e+02 7.0000e-02 9.1000e+01\n 8.0000e-02 7.2500e+00 1.2000e+02 3.3000e-01 4.0250e+01 1.5700e+00\n 1.0500e+01 9.8000e-01 3.0000e+00 6.5000e-01 3.0000e-02 4.5720e+01\n 4.6600e+01 8.4820e+01 4.2000e-01 2.5000e+00 1.8480e+01 5.8300e+00\n 8.0000e-02 1.2600e+02 1.8000e+00 5.7900e+00 1.4200e+01 4.8000e+01\n 4.1800e+00 1.5200e+02 3.0000e-02 3.6200e+00 1.0540e+01 1.2000e-01\n 3.0620e+01 1.3581e+02 1.7100e+02 1.4000e+01 3.2400e+00 1.9500e+02\n 5.0000e-02 8.6000e+01 1.2157e+02 1.4000e-01 7.7000e+00 9.6500e+02\n 2.0000e+01 2.0000e+00 2.5700e+01 1.4300e+02 7.6300e+00 1.0000e-03\n 2.5000e-01 1.0000e+01 9.8500e+00 1.5000e-01 2.1660e+01 1.7240e+01\n 2.2800e+02 1.0400e+02 1.6700e+00 2.1510e+01 2.5000e-01 3.3000e-01\n 1.3000e+00 1.1400e+00 2.7850e+01 1.8840e+02 9.3000e-01 3.0000e-02\n 2.9900e+00 2.0000e-01 3.3000e+01 1.1600e+00 3.2890e+01 7.5000e-03\n 2.0000e-02 7.0000e-02 5.0000e-01 1.0200e+01 1.6000e+00 2.5000e-01\n 1.8200e+00 1.0000e-02 8.8170e+01 1.8000e+00 3.1100e+02 1.0400e-01\n 4.3900e+01 8.5400e+02 6.6200e+00 8.5500e+00 2.4000e-01 4.1040e+01\n 1.3400e+00 5.9200e+00 2.7000e-01 4.0400e+00 2.4000e+01 5.0000e-02\n 4.1000e+01 7.5110e+01 4.2180e+01 6.0000e+00 4.6800e+01 2.3000e+01\n 3.3100e+00 9.1260e+01 1.1000e-01 1.7000e+01 3.2700e+00 3.2600e+00\n 2.8410e+01 3.2920e+01 6.5000e-01 1.5316e+02 2.9161e+02 1.1900e+02\n 3.0000e+01 1.2414e+02 1.0540e+01 6.1000e-01 2.2700e+00 2.7000e-01\n 2.4000e+00 2.1026e+02 6.4500e+01 2.5000e+01 1.2500e+02 1.7810e+02\n 1.9400e+01 1.2700e+00 1.2300e+02 2.5000e+00 1.0900e+01 3.1900e+00\n 1.0000e-01 1.2600e+01 2.2000e-01 1.0000e+01 1.5318e+02 1.7000e-01\n 5.0000e-02 4.7100e+01 7.0000e+00 9.6800e+01 5.0000e-01 8.1700e+00\n 1.2600e+02 1.0220e+01 3.1600e+01 8.5200e+01 3.8000e+01 3.7685e+02\n 2.8000e-01 1.5000e+01 1.2000e-01 1.4298e+02 5.0000e+00 9.4850e+01\n 5.6710e+01 2.1000e+03 2.5840e+01 3.9760e+01 2.2700e+01 4.9470e+01\n 2.8600e+00 1.5732e+02 6.0000e-01 9.0000e-02 2.6100e+01 3.0000e+00\n 4.0800e+01 5.5000e-01 6.0770e+01 4.7000e+01 1.4695e+02 2.8700e+01\n 6.0000e-01 5.0000e-01 4.9000e+00 3.1150e+01 6.2500e+00 1.0000e+01\n 5.0000e+00 1.9800e+01 4.3100e+00 2.7000e+01 8.6000e-01 2.1200e+02\n 1.1580e+01 9.0000e-02 4.0000e-01 3.6000e+00 2.1114e+02 8.1650e+01\n 1.4000e-01 2.1000e+02 1.4760e+01 3.1400e+00 1.2000e+01 3.7700e+00\n 1.7000e-01 5.0000e+00 1.0000e-01 7.2600e+01 4.9590e+01 1.7473e+02\n 2.2400e+00 2.0709e+02 3.0300e+02 4.0000e+00 5.0000e+00 4.2000e-01\n 3.3500e+00 2.9000e-01 2.0000e+00 1.2500e+00 1.5000e-01 1.2000e+01\n 8.0000e-01 7.3000e+01 3.9000e-01 3.6500e+01 2.4100e+00 6.0000e+01\n 2.1600e+02 1.3900e+02 5.0000e+00 3.6000e+01 7.8900e+01 9.0300e+00\n 4.3240e+02 8.3000e+01 7.0000e-01 4.7170e+01 2.8730e+01 4.1200e+00\n 7.5000e-01 2.1656e+02 3.4206e+02 6.4000e-01 5.3700e+00 9.3000e+01\n 3.5000e+00 8.0000e+01 1.3700e+01 6.2790e+01 1.4100e+02 2.4400e+00\n 1.0398e+02 2.0000e+00 2.0000e+01 4.3100e+00 2.2200e+02 3.7000e+01\n 4.6400e+01 8.0430e+01 3.1855e+02 1.2200e+00 2.5700e+00 1.5000e-01\n 5.0000e-02 5.0000e+00 5.7500e+00 2.0600e+02 2.0380e+01 9.0000e-02\n 1.2000e+01 2.1600e+02 1.1300e+00 3.0000e+00 7.4000e+01 2.9000e+01\n 3.4000e-01 5.8800e+01 1.0362e+02 4.5700e+00 9.8200e+00 9.9700e+01\n 4.6800e+00 9.6900e+02 1.2000e-01 2.1000e-01 2.3000e-01 3.3140e+01\n 1.2700e+01 9.6660e+01 1.5275e+02 2.0000e+02 1.4613e+02 3.5000e-01\n 3.8000e+00 3.5000e-01 1.2400e+01 2.8000e+00 8.0000e+00 1.9504e+02\n 1.0400e+00 1.0000e-01 3.1070e+01 4.0000e-01 1.2300e+00 9.2500e-01\n 4.3200e+00 4.0000e-01 1.3400e+00 1.3100e+01 6.0000e-02 4.0000e-02\n 3.1000e-01 2.2000e-01 8.0000e+00 6.5000e+01 2.2000e+01 4.8000e+00\n 8.3000e-02 6.5000e-01 1.0000e+01 1.0000e+00 1.7000e+01 1.2090e+01\n 1.7500e+01 5.4000e+01 2.3500e-01 2.0000e-01 1.8750e+01 3.4600e+00\n 2.5700e+00 4.0000e-01 9.3840e+01 1.2270e+01 1.2400e+00 1.5600e+00\n 1.9500e+00 5.1000e+00 3.0000e+01 1.9860e+01 7.0000e+00 2.2400e+01\n 9.0000e-01 4.2700e+00 3.0610e+01 1.0060e+01 1.0000e+02 3.3406e+02\n 1.0000e+00 1.3500e+00 1.4500e+00 1.9300e+02 3.6000e-01 6.5000e-03\n 8.0880e+01 8.5000e-02 1.9300e+00 1.2000e-01 3.2000e-01 3.0350e+01\n 1.5300e+02 2.0000e-01 2.9500e+00 4.6000e+01 3.8000e+01 1.3900e-01\n 8.7020e+01 2.2900e+00 3.7700e+01 1.3480e+00 4.0000e+00 6.5700e+01\n 7.6000e-01 7.0000e+00 1.1460e+01 1.5300e+02 1.5143e+02 7.6600e+00\n 2.5600e+01 1.8100e+00 2.0100e+01 2.0000e-02 3.5620e+02 3.0000e-03\n 1.5000e+00 9.7180e+01 9.5000e-01 2.8000e-01 1.5000e+01 1.0000e+01\n 3.9000e-01 5.2500e+00 1.0000e-03 4.3900e+00 1.7000e-01 4.4920e+01\n 7.1000e+01 1.7800e+00 1.3000e+00 4.7500e+00 2.0000e+01 2.8060e+01\n 3.0000e+00 2.5000e+00 2.5000e+00 5.0000e-01 7.2000e-01 3.5300e+01\n 1.2900e+00 2.8400e+00 3.0490e+01 6.4900e+01 1.0900e+00 2.8027e+02\n 2.1600e+01 3.5000e+00 2.1320e+01 4.3000e+01 4.7000e-01 9.6000e-01\n 2.0000e-01 1.9400e+01 1.6310e+01 4.7000e-01 2.0000e+00 1.1000e-01\n 1.6500e+00 4.7820e+01 3.4130e+01 6.6800e+00 5.0000e-01 1.2000e-01\n 4.6230e+01 9.0000e+00 1.3900e+00 2.6000e-01 9.1000e-01 1.2920e+01\n 5.0840e+01 2.1300e+00 2.0000e+01 8.3000e-02 1.5000e-01 2.2759e+02\n 1.5750e+01 5.5000e+00 9.0000e+00 1.6500e+01 5.0000e-01 6.8000e+00\n 5.0000e-03 5.7000e-01 1.7500e+01 5.2437e+02 7.2100e+01 1.5000e+02\n 8.4800e+00 1.9100e+00 4.2000e-01 2.5041e+02 1.8200e+00 2.8000e+01\n 1.2000e+01 1.3530e+01 3.4500e+00 9.3900e+00 2.4000e+01 4.7000e+01\n 1.5500e+01 2.0000e-02 9.0000e-02 1.1060e+01 9.4000e+01 7.5000e+01\n 3.6960e+01 5.0000e-03 4.8000e-01 1.0600e+01 7.1000e+01 2.5900e+01\n 3.9870e+01 7.9000e+01 1.1000e+00 9.5800e+00 2.0148e+02 2.3000e-01\n 4.9000e+01 1.7000e+01 2.3756e+02 1.1800e+00 8.4800e+00 1.3380e+01\n 6.4540e+01 1.1170e+02 7.5000e-03 1.3849e+02 1.9500e+01 3.4500e+01\n 2.4000e-01 1.2000e-01 3.3000e+01 1.1100e+00 8.0000e-01 4.0000e-01\n 2.7200e+00 4.1800e+01 5.1582e+02 2.1800e+00 7.5700e+01 3.8302e+02\n 4.8000e+01 6.3590e+01 1.3200e+00 2.7600e+00 8.1000e-02 1.2300e+00\n 2.0700e+02 1.6148e+02 5.5800e+02 2.2000e-01 8.6030e+01 8.1000e+01\n 1.7000e+01 3.8030e+01 9.9900e+00 7.8000e+01 1.4500e+02 4.4000e-01\n 6.0000e+00 1.5000e-01 1.0000e+01 2.8800e+01 8.9500e+00 6.2000e-01\n 1.9200e+00 3.0000e-02 2.4520e+01 9.1500e+00 2.6800e+00 3.2580e+01\n 5.0000e-02 1.2870e+01 2.3010e+01 8.2400e+00 1.2000e-02 1.5500e+00\n 1.6876e+02 1.7000e+01 2.0000e+00 3.7000e-01 1.7500e+02 1.8800e+00\n 1.1500e+02 7.6000e-01 1.0740e+02 4.3964e+02 4.6500e+01 1.7590e+02\n 2.4960e+01 1.5000e+01 9.2400e+00 2.0000e+00 1.0066e+02 6.0000e+00\n 1.1100e+00 3.0250e-01 3.4000e-01 5.8200e+01 3.8000e+01 9.9250e+01\n 2.0893e+02 6.7560e+01 1.1000e-01 1.0500e+00 4.2900e+01 1.3600e+02\n 1.3000e-01 1.7000e+02 2.5300e+00 1.4900e+00 2.3050e+01 1.5300e+00\n 2.9700e+01 1.0000e-01 5.0000e-02 1.1000e+02 3.9592e+02 4.1000e+01\n 1.1076e+02 1.5000e-01 7.0000e-03 1.4000e+01 2.2000e+01 7.1000e-01\n 6.0000e-01 8.4000e+01 5.0000e-01 1.8000e+01 2.0000e-03 1.0000e-01\n 3.7000e+01 3.0000e+01 1.2000e+01 1.3000e+00 7.7000e-01 7.1000e+01\n 5.0000e-02 5.0610e+01 5.2000e+00 6.1500e+00 3.0000e-01 2.2260e+01\n 9.0000e-02 2.5000e-01 1.0500e+00 3.3500e+02 1.1380e+01 2.4500e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the Training set results\n",
    "\n",
    "plt.scatter(basic_X_train['box_office'], basic_y_train, color='red')\n",
    "plt.plot(basic_X_train['box_office'].values.reshape(-1, 1), regressor.predict(basic_X_train['box_office']), color='blue')\n",
    "plt.title('Box Office vs Budget (Training Set)')\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Box Office')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Visualizing the Test set results\n",
    "\n",
    "plt.scatter(basic_X_validate['box_office'], basic_y_validate, color='red')\n",
    "plt.plot(basic_X_train['box_office'].values.reshape(-1, 1), regressor.predict(basic_X_train['box_office']), color='blue')\n",
    "plt.title('Box Office vs Budget (Test Set)')\n",
    "plt.xlabel('Budget')\n",
    "plt.ylabel('Box Office')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train.box_office, train.success\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.15)\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e-06],\n",
       "       [1.e-05],\n",
       "       [1.e-04],\n",
       "       [1.e-03],\n",
       "       [1.e-02],\n",
       "       [1.e-01],\n",
       "       [5.e-01],\n",
       "       [1.e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1,0.5, 1]\n",
    "alphas = np.array(alphas).reshape(-1, 1)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((961, 1), (961, 1), (8, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha  :  [1.e-06],   R2  :  0.17592282873741505,   MSE   :   0.20306905654869947,   RMSE   :   0.4506318414722815\n",
      "Alpha  :  [1.e-05],   R2  :  0.1759228287199992,   MSE   :   0.2030690565529911,   RMSE   :   0.4506318414770433\n",
      "Alpha  :  [0.0001],   R2  :  0.17592282697871453,   MSE   :   0.20306905698207836,   RMSE   :   0.45063184195313843\n",
      "Alpha  :  [0.001],   R2  :  0.17592265316608102,   MSE   :   0.20306909981297908,   RMSE   :   0.4506318894762987\n",
      "Alpha  :  [0.01],   R2  :  0.17590558309218984,   MSE   :   0.20307330621975891,   RMSE   :   0.45063655668371927\n",
      "Alpha  :  [0.1],   R2  :  0.17446892106207368,   MSE   :   0.20342732840749655,   RMSE   :   0.4510291879773376\n",
      "Alpha  :  [0.5],   R2  :  0.15637584776674762,   MSE   :   0.20788582265084407,   RMSE   :   0.45594497765722136\n",
      "Alpha  :  [1.],   R2  :  0.1319421215531934,   MSE   :   0.21390678027857898,   RMSE   :   0.46250057327378413\n"
     ]
    }
   ],
   "source": [
    "for a in alphas:\n",
    " model = Ridge(alpha=a, normalize=True).fit(x,y)\n",
    " score = model.score(x, y)\n",
    " pred_y = model.predict(x)\n",
    " mse = mean_squared_error(y, pred_y) \n",
    " print(f\"Alpha  :  {a},   R2  :  {score},   MSE   :   {mse},   RMSE   :   {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['box_office']\n",
    "y = train['success']\n",
    "\n",
    "X = np.array(X).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of training data :  0.45318799514739466\n",
      "R2 score value of training data :  0.16606543694518028\n",
      "RMSE value of testing data :  0.4479581521217403\n",
      "R2 score value of testing data :  0.1867300440607449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model_lasso = Lasso(alpha=0.01)\n",
    "model_lasso.fit(X_train, y_train) \n",
    "pred_train_lasso= model_lasso.predict(X_train)\n",
    "print(\"RMSE value of training data : \", np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(\"R2 score value of training data : \",r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test)\n",
    "print(\"RMSE value of testing data : \",np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(\"R2 score value of testing data : \",r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "R = Ridge(alpha=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.0001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.fit(basic_X_train, basic_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = R.predict(basic_X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.051496627985832766\n",
      "RMSE 0.48118256516116625\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 score\", r2_score(basic_y_validate, y_pred1))\n",
    "print(\"RMSE\", np.sqrt(mean_squared_error(basic_y_validate, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 241 entries, 348 to 734\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   runtime     241 non-null    int32  \n",
      " 1   budget      241 non-null    float64\n",
      " 2   box_office  241 non-null    float64\n",
      " 3   votes       241 non-null    int64  \n",
      "dtypes: float64(2), int32(1), int64(1)\n",
      "memory usage: 8.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((241, 4),\n",
       " (241,),\n",
       " None,\n",
       " 348    1\n",
       " 132    0\n",
       " 532    0\n",
       " 386    0\n",
       " 325    1\n",
       "       ..\n",
       " 421    0\n",
       " 2      1\n",
       " 375    1\n",
       " 262    0\n",
       " 734    1\n",
       " Name: success, Length: 241, dtype: int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_X_validate.shape, basic_y_validate.shape, basic_X_validate.info(), basic_y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348    64.00\n",
       "132    19.00\n",
       "532     3.75\n",
       "386    11.00\n",
       "325    30.00\n",
       "       ...  \n",
       "421     5.00\n",
       "2      18.00\n",
       "375    12.00\n",
       "262     3.00\n",
       "734    20.00\n",
       "Name: budget, Length: 241, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_X_validate['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization on test set     \n",
    "plt.scatter( basic_X_validate['box_office'], basic_y_validate, color = 'blue' )    \n",
    "plt.scatter( basic_X_validate['box_office'], y_pred1, color = 'orange' )    \n",
    "plt.title( 'Salary vs Experience' )    \n",
    "plt.xlabel( 'Years of Experience' )    \n",
    "plt.ylabel( 'Salary' )    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [241, 720]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b6eadad69932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogreg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasic_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [241, 720]"
     ]
    }
   ],
   "source": [
    "logreg2 = LogisticRegression(C = 0.001, penalty=\"l2\")\n",
    "logreg2.fit(basic_X_train, basic_y_train)\n",
    "print(\"score\", logreg2.score(basic_X_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "regressor.fit(basic_X_train, basic_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "test_data_prediction = regressor.predict(basic_X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_score = metrics.r2_score(basic_y_validate, test_data_prediction)\n",
    "print(\"R squared error : \", error_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_y_validate = list(basic_y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(basic_y_validate, color='red', label = 'Actual Value')\n",
    "plt.plot(test_data_prediction, color='yellow', label='Predicted Values')\n",
    "plt.title('Actual Box Office vs Predicted Box Office')\n",
    "plt.xlabel('Number of values')\n",
    "plt.ylabel('Success')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = pd.read_csv('bollywood_data.csv')\n",
    "genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping columns which are not useful\n",
    "genres_df = genres_df.drop(['title_x','title_y', 'imdb_id', 'poster_path', 'wiki_link', 'is_adult', 'tagline', 'release_date', 'story', 'summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming columns for ease of references\n",
    "genres_df = genres_df.rename(columns={'original_title':'title', 'year_of_release':'year', 'imdb_rating':'rating', 'imdb_rating':'rating', 'imdb_votes':'votes', 'wins_nominations':'awards'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "genres_df['box_office'] = genres_df['box office']\n",
    "genres_df = genres_df.drop(['box office'], axis = 1)\n",
    "genres_df['awards'] = genres_df['awards'].apply(lambda x : re.sub(r'[A-Za-z]', '', str(x)))\n",
    "\n",
    "genres_df[['wins', 'nominations']] = genres_df.awards.str.split('&', expand= True)\n",
    "\n",
    "genres_df['wins'] = genres_df['wins'].str.strip()\n",
    "genres_df['wins'] = genres_df['wins'].apply(lambda x: 0 if x=='' else x)\n",
    "genres_df['wins'] = genres_df['wins'].replace(np.nan, 0)\n",
    "genres_df['wins'] = genres_df['wins'].astype(int)\n",
    "genres_df['nominations'] = genres_df['nominations'].replace(np.nan, 0)\n",
    "genres_df['nominations'] = genres_df['nominations'].astype(int)\n",
    "\n",
    "genres_df['runtime'] = genres_df['runtime'].replace('\\\\N', np.nan)\n",
    "genres_df['runtime'] = genres_df['runtime'].ffill()\n",
    "genres_df['runtime'] = genres_df['runtime'].astype(int)\n",
    "genres_df = genres_df[genres_df['runtime'] >= 60]\n",
    "\n",
    "actors = genres_df.actors.str.split('|', expand=True)\n",
    "\n",
    "genres_df = genres_df.drop(['awards', 'actors', 'nominations'], axis=1)\n",
    "\n",
    "genres_df = genres_df[genres_df['year'] >= 2009]\n",
    "genres_df = genres_df.drop_duplicates()\n",
    "\n",
    "genres_df[\"success\"] = np.where(\n",
    "   (genres_df.box_office > genres_df.budget), \n",
    "   \"1\", \n",
    "   \"0\"\n",
    ")\n",
    "genres_df['success'] = genres_df['success'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action = []\n",
    "Adventure = []\n",
    "Animation = []\n",
    "Biography = []\n",
    "Comedy = []\n",
    "Crime = []\n",
    "Drama = []\n",
    "Family = []\n",
    "Fantasy = []\n",
    "History = []\n",
    "Horror = []\n",
    "Music = []\n",
    "Musical = []\n",
    "Mystery = []\n",
    "Romance = []\n",
    "SciFi = []\n",
    "Short = []\n",
    "Sport = []\n",
    "Thriller = []\n",
    "War = []\n",
    "for row in genres_df['genres']:\n",
    "    row == row.split(\"|\")\n",
    "    if 'Action' in row: \n",
    "        \n",
    "        Action.append('1')\n",
    "    else:\n",
    "        Action.append('0')\n",
    "    if 'Adventure' in row:    \n",
    "        Adventure.append('1')\n",
    "    else:\n",
    "        Adventure.append('0')\n",
    "    if 'Animation' in row:    \n",
    "        Animation.append('1')\n",
    "    else:\n",
    "        Animation.append('0')\n",
    "    if 'Biography' in row:    \n",
    "        Biography.append('1')\n",
    "    else:\n",
    "        Biography.append('0')\n",
    "    if 'Comedy' in row:    \n",
    "        Comedy.append('1')\n",
    "    else:\n",
    "        Comedy.append('0')\n",
    "    if 'Crime' in row:    \n",
    "        Crime.append('1')\n",
    "    else:\n",
    "        Crime.append('0')\n",
    "    if 'Drama' in row:    \n",
    "        Drama.append('1')\n",
    "    else:\n",
    "        Drama.append('0')\n",
    "    if 'Family' in row:    \n",
    "        Family.append('1')\n",
    "    else:\n",
    "        Family.append('0')\n",
    "    if 'Fantasy' in row:    \n",
    "        Fantasy.append('1')\n",
    "    else:\n",
    "        Fantasy.append('0')\n",
    "    if 'History' in row:    \n",
    "        History.append('1')\n",
    "    else:\n",
    "        History.append('0')    \n",
    "    if 'Horror' in row:    \n",
    "        Horror.append('1')\n",
    "    else:\n",
    "        Horror.append('0') \n",
    "    if 'Music' in row:    \n",
    "        Music.append('1')\n",
    "    else:\n",
    "        Music.append('0')\n",
    "    if 'Musical' in row:    \n",
    "        Musical.append('1')\n",
    "    else:\n",
    "        Musical.append('0')\n",
    "    if 'Mystery' in row:    \n",
    "        Mystery.append('1')\n",
    "    else:\n",
    "        Mystery.append('0')\n",
    "    if 'Romance' in row:    \n",
    "        Romance.append('1')\n",
    "    else:\n",
    "        Romance.append('0')\n",
    "    if 'Sci-Fi' in row:    \n",
    "        SciFi.append('1')\n",
    "    else:\n",
    "        SciFi.append('0')\n",
    "    if 'Short' in row:    \n",
    "        Short.append('1')\n",
    "    else:\n",
    "        Short.append('0')\n",
    "    if 'Sport' in row:    \n",
    "        Sport.append('1')\n",
    "    else:\n",
    "        Sport.append('0')\n",
    "    if 'Thriller' in row:    \n",
    "        Thriller.append('1')\n",
    "    else:\n",
    "        Thriller.append('0')\n",
    "    if 'War' in row:    \n",
    "        War.append('1')\n",
    "    else:\n",
    "        War.append('0')\n",
    "        \n",
    "genres_df[\"Action\"] = Action\n",
    "genres_df[\"Adventure\"] = Adventure\n",
    "genres_df[\"Animation\"] = Animation\n",
    "genres_df[\"Biography\"] = Biography\n",
    "genres_df[\"Comedy\"] = Comedy\n",
    "genres_df[\"Crime\"] = Crime\n",
    "genres_df[\"Drama\"] = Drama\n",
    "genres_df[\"Family\"] = Family\n",
    "genres_df[\"Fantasy\"] = Fantasy\n",
    "genres_df[\"History\"] = History\n",
    "genres_df[\"Horror\"] = Horror\n",
    "genres_df[\"Music\"] = Music\n",
    "genres_df[\"Musical\"] = Musical\n",
    "genres_df[\"Mystery\"] = Mystery\n",
    "genres_df[\"Romance\"] = Romance\n",
    "genres_df[\"Sci-Fi\"] = SciFi\n",
    "genres_df[\"Short\"] = Short\n",
    "genres_df[\"Sport\"] = Sport\n",
    "genres_df[\"Thriller\"] = Thriller\n",
    "genres_df[\"War\"] = War\n",
    "\n",
    "genres_df['Action'] =genres_df['Action'].astype(int)\n",
    "genres_df['Adventure'] =genres_df['Adventure'].astype(int)\n",
    "genres_df['Animation'] =genres_df['Animation'].astype(int)\n",
    "genres_df['Biography'] =genres_df['Biography'].astype(int)\n",
    "genres_df['Comedy'] =genres_df['Comedy'].astype(int)\n",
    "genres_df['Crime'] =genres_df['Crime'].astype(int)\n",
    "genres_df['Drama'] =genres_df['Drama'].astype(int)\n",
    "genres_df['Family'] =genres_df['Family'].astype(int)\n",
    "genres_df['Fantasy'] =genres_df['Fantasy'].astype(int)\n",
    "genres_df['History'] =genres_df['History'].astype(int)\n",
    "genres_df['Horror'] =genres_df['Horror'].astype(int)\n",
    "genres_df['Music'] =genres_df['Music'].astype(int)\n",
    "genres_df['Musical'] =genres_df['Musical'].astype(int)\n",
    "genres_df['Mystery'] =genres_df['Mystery'].astype(int)\n",
    "genres_df['Romance'] =genres_df['Romance'].astype(int)\n",
    "genres_df['Sci-Fi'] =genres_df['Sci-Fi'].astype(int)\n",
    "genres_df['Short'] =genres_df['Short'].astype(int)\n",
    "genres_df['Sport'] =genres_df['Sport'].astype(int)\n",
    "genres_df['Thriller'] =genres_df['Thriller'].astype(int)\n",
    "genres_df['War'] =genres_df['War'].astype(int)\n",
    "\n",
    "genres_df = genres_df.drop(['genres'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
